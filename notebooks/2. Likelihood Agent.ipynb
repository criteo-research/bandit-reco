{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install recogym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood-based models\n",
    "\n",
    "This notebook will outline the likelihood-based approach to training on Bandit feedback.\n",
    "\n",
    "Although before proceeding, we will study the output of the simulator in a little more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random.mtrand import RandomState\n",
    "from recogym import Configuration\n",
    "from recogym.agents import Agent\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from recogym import verify_agents\n",
    "from recogym.agents import OrganicUserEventCounterAgent, organic_user_count_args\n",
    "from recogym.agents import RandomAgent, random_args\n",
    "from recogym.evaluate_agent import verify_agents, plot_verify_agents\n",
    "\n",
    "import gym, recogym\n",
    "from copy import deepcopy\n",
    "from recogym import env_1_args\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams['figure.figsize'] = [6, 3]\n",
    "\n",
    "num_users = 1000\n",
    "\n",
    "env_1_args['number_of_flips'] = 0\n",
    "env_1_args['sigma_mu_organic'] = 0.0\n",
    "env_1_args['sigma_omega'] = 1\n",
    "env_1_args['random_seed'] = 42\n",
    "env_1_args['num_products'] = 10\n",
    "env_1_args['K'] = 5\n",
    "env_1_args['number_of_flips'] = 5\n",
    "\n",
    "env = gym.make('reco-gym-v1')\n",
    "env.init_gym(env_1_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = deepcopy(env).generate_logs(num_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "## Turn Data into Features\n",
    "\n",
    "Now we are going to build a _Logistic Regression_ model.\n",
    "\n",
    "The model will predict _the probability of the click_ for the following data:\n",
    "* _`Views`_ is a total amount of views of a particular _`Product`_ shown during _Organic_ _`Events`_ **before** a _Bandit_ _`Event`_.\n",
    "* _`Action`_ is a proposed _`Product`_ at a _Bandit_ _`Event`_.\n",
    "\n",
    "For example, assume that we have _`10`_ products. In _Organic_ _`Events`_ , these products  were shown to a user as follows:\n",
    "\n",
    "| Product Id | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8  | 9 |\n",
    "|------------|---|---|---|---|---|---|---|---|----|---|\n",
    "| Views      | 0 | 0 | 0 | 7 | 0 | 0 | 0 | 8 | 11 | 0 |\n",
    "\n",
    "When we want to know the probability of the click for _`Product`_ = _`8`_ with available amounts of _`Views`_ , the input data for the model will be:\n",
    "\n",
    "$v = $_`0 0 0 7 0 0 0 8 11 0`_ and _**`8`**_\n",
    "\n",
    "The first `10` numbers are _`Views`_ of _`Products`_ (see above), the latest one is the _`Action`_.\n",
    "\n",
    "We will try to predict: $\\mathbb{P}(C|P=p, V)$ that is the probability of the click for a _`Product`_ $p$, provided that we have _`Views`_ $V$.\n",
    "\n",
    "We will encode _`Action`_ using a one-hot encoding.\n",
    "In our current example, the _`Action`_ is _`8`_. Thus, it is encoded as:\n",
    "\n",
    "_$a = $`0 0 0 0 0 0 0 0`_ _**`1`**_ _`0`_\n",
    "\n",
    "Here,\n",
    "* Vector of _`Actions`_ has a size that is equal to the _*number of `Products`*_ i.e., _`10`_.\n",
    "* _`Action`_ _`8`_ is marked as _`1`_ (_`Action`_ starts with _`0`_ ).\n",
    "\n",
    "Numerically, to fully describe the context $P=p, V$ that mixes the evaluated product and the products seen by the user, we do a Kronecker product of the two vectors $a$ and $v$. \n",
    "Namely, the vector used as features is the flattened version of the following $P \\times P$ matrix\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "\\cdots & 0      & \\cdots \\\\\n",
    "  & \\vdots & \\\\\n",
    "\\cdots & v & \\cdots \\\\\n",
    "  & \\vdots & \\\\\n",
    "\\cdots & 0      & \\cdots\n",
    "\\end{pmatrix}\n",
    "\\leftarrow \\text{ only the line corresponding the the action $p$ is non zero}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recogym.agents import FeatureProvider\n",
    "\n",
    "class CountFeatureProvider(FeatureProvider):\n",
    "    \"\"\"Feature provider as an abstract class that defines interface of setting/getting features\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(CountFeatureProvider, self).__init__(config)\n",
    "        self.feature_data = np.zeros((self.config.num_products))\n",
    "\n",
    "    def observe(self, observation):\n",
    "        \"\"\"Consider an Organic Event for a particular user\"\"\"\n",
    "        for session in observation.sessions():\n",
    "            self.feature_data[int(session['v'])] += 1\n",
    "\n",
    "    def features(self, observation):\n",
    "        \"\"\"Provide feature values adjusted to a particular feature set\"\"\"\n",
    "        return self.feature_data\n",
    "\n",
    "    def reset(self):\n",
    "        self.feature_data = np.zeros((self.config.num_products))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from recogym import Configuration, DefaultContext, Observation\n",
    "from recogym.envs.session import OrganicSessions\n",
    "\n",
    "\n",
    "def build_train_data(logs, feature_provider):\n",
    "    user_states, actions, rewards, proba_actions = [], [], [], []\n",
    "\n",
    "    current_user = None\n",
    "    for _, row in logs.iterrows():\n",
    "        if current_user != row['u']:\n",
    "            # User has changed: start a new session and reset user state.\n",
    "            current_user = row['u']\n",
    "            sessions = OrganicSessions()\n",
    "            feature_provider.reset()\n",
    "\n",
    "        context = DefaultContext(row['u'], row['t'])\n",
    "\n",
    "        if row['z'] == 'organic':\n",
    "            sessions.next(context, row['v'])\n",
    "\n",
    "        else:\n",
    "            # For each bandit event, generate one observation for the user state, \n",
    "            # the taken action the obtained reward and the used probabilities.\n",
    "            feature_provider.observe(Observation(context, sessions))\n",
    "            user_states.append(feature_provider.features(None).copy())\n",
    "            actions.append(row['a'])\n",
    "            rewards.append(row['c'])\n",
    "            proba_actions.append(row['ps'])\n",
    "\n",
    "            # Start a new organic session.\n",
    "            sessions = OrganicSessions()\n",
    "\n",
    "    return np.array(user_states), np.array(actions).astype(int), np.array(rewards), np.array(proba_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can now see data that will be provided to our agents based on logistic regressions.\n",
    "config = Configuration(env_1_args)\n",
    "count_feature_provider = CountFeatureProvider(config=config)\n",
    "\n",
    "user_states, actions, rewards, proba_actions = build_train_data(data, count_feature_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_start, preview_size = 500, 3\n",
    "\n",
    "print('User product views count at action time:')\n",
    "print(user_states[preview_start:preview_start + preview_size])\n",
    "print('Taken actions: ', actions[preview_start:preview_start + preview_size])\n",
    "print('Obtained rewards: ', rewards[preview_start:preview_start + preview_size])\n",
    "print('Probablities of the taken actions: ', proba_actions[preview_start:preview_start + preview_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data and see how it maps into the features - which is the combination of the history and the actions and the label, which is clicks.  Note that only the bandit events correspond to records in the training data.\n",
    "\n",
    "To make a personalization, it is necessary to cross the action and history features. _Why_ ?  We do the simplest possible to cross an element-wise Kronecker product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LikelihoodAgent(Agent):\n",
    "    def __init__(self, feature_provider, seed=43):\n",
    "        self.feature_provider = feature_provider\n",
    "        self.random_state = RandomState(seed)\n",
    "        self.model = None\n",
    "        \n",
    "    @property\n",
    "    def num_products(self):\n",
    "        return self.feature_provider.config.num_products\n",
    "    \n",
    "    def _create_features(self, user_state, action):\n",
    "        \"\"\"Create the features that are used to estimate the expected reward from the user state\"\"\"\n",
    "        features = np.zeros(len(user_state) * self.num_products)\n",
    "        features[action * len(user_state): (action + 1) * len(user_state)] = user_state\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def train(self, logs):\n",
    "        user_states, actions, rewards, proba_actions = build_train_data(logs, self.feature_provider)\n",
    "        \n",
    "        features = np.vstack([\n",
    "            self._create_features(user_state, action) \n",
    "            for user_state, action in zip(user_states, actions)\n",
    "        ])\n",
    "        self.model = LogisticRegression(solver='lbfgs', max_iter=5000)\n",
    "        self.model.fit(features, rewards)\n",
    "    \n",
    "    def _score_products(self, user_state):\n",
    "        all_action_features = np.array([\n",
    "            # How do you create the features to feed the logistic model ?\n",
    "            for action in range(self.num_products)\n",
    "        ])\n",
    "        return self.model.predict_proba(all_action_features)[:, 1]\n",
    "        \n",
    "    def act(self, observation, reward, done):\n",
    "        \"\"\"Act method returns an action based on current observation and past history\"\"\"\n",
    "        self.feature_provider.observe(observation)        \n",
    "        user_state = self.feature_provider.features(observation)\n",
    "        \n",
    "        # Question 1.\n",
    "        # Insert code to evaluate the click through rate of every action\n",
    "        \n",
    "        # Question 2.\n",
    "        # Why do we set the propsity score to 1.0?\n",
    "        \n",
    "        # Question 3.\n",
    "        # How would you implement epsilong greedy?\n",
    "        \n",
    "        ps = 1.0\n",
    "        all_ps = np.zeros(self.num_products)\n",
    "        all_ps[action] = 1.0        \n",
    "        \n",
    "        return {\n",
    "            **super().act(observation, reward, done),\n",
    "            **{\n",
    "                'a': action,\n",
    "                'ps': ps,\n",
    "                'ps-a': all_ps,\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def reset(self):\n",
    "        self.feature_provider.reset()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the feature vector used by the Likelihood agent.\n",
    "picked_sample = 500\n",
    "\n",
    "count_product_views_feature_provider = CountFeatureProvider(config)\n",
    "likelihood_logreg = LikelihoodAgent(count_product_views_feature_provider)\n",
    "\n",
    "print('User state: ', user_states[picked_sample])\n",
    "print('Action: ', actions[picked_sample])\n",
    "print('Created cross features:')\n",
    "print(likelihood_logreg._create_features(user_states[picked_sample], actions[picked_sample]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "likelihood_logreg = LikelihoodAgent(count_product_views_feature_provider)\n",
    "likelihood_logreg.train(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organic_counter_agent = OrganicUserEventCounterAgent(\n",
    "    Configuration({\n",
    "        **organic_user_count_args,\n",
    "        **env_1_args,\n",
    "        'select_randomly': True,\n",
    "    })\n",
    ")\n",
    "\n",
    "random_agent = RandomAgent(Configuration(random_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = verify_agents(\n",
    "    env,\n",
    "    number_of_users=2000,\n",
    "    agents={\n",
    "        'random agent': random_agent,\n",
    "        'Organic Count': organic_counter_agent,\n",
    "        'Likelihood LogReg': likelihood_logreg,\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_verify_agents(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
